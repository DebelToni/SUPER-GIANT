<h1 align="center">SUPER GIANT</h1>
<!-- <p align="center"> SUPERsupreme Utra PROfesional ELITE ReVolutIonary GIGA intelligent ArtIfical neXus TITAN </p> -->

GIANT is my custom implementation of a large language model (LLM) written in Python - JAX.
It is designed to be efficient, scalable and robust, with a focus on performance on a single GPU and ease of use.
<br>
<br>
Right now it is in an active state of development with working on v1 - the 'second' version of the model which greatly improves v0 in terms of performance and flexability.
<br><br>
## Architecture
- Classic Decoder-only transformer architecture
> [!NOTE]
> Future Architectural Ides:
> - Mixture of Experts (MoE) layers
> - My custom idea of 'Cross-contextual' attention
> - Real time access of tools at inference time (in the TTC)

