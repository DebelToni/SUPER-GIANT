❯ python model/Run_training.py
Starting training...
Setting up JAX...
Entering get_data()
Loaded dataset with 2141709 examples
Encoded 22111 sequences of length 512 tokens
train batches: 21447  val batches: 664
Initialising model parameters and optimizer...
Training for 1 epochs with 64 batch size
step     200 | loss nan
✓ Epoch 1 done – val loss nan  ppl nan
✔ parameters & tokenizer saved

❯ python model/Generate_text.py
Once upon a time!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

❯ python model/Generate_text.py "The quick brown fox jumped over the lazy "
The quick brown fox jumped over the lazy!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
